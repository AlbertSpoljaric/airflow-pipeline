language: python

python:
- '2.7'

branches:
  only:
  - master

services:
- docker

env:
- AIRFLOW_VERSION=1.9.0
  SPARK_VERSION=1.6.3
  HADOOP_VERSION=2.6.5
  SPARK_PY4J=python/lib/py4j-0.9-src.zip
  DOCKER_TAGS="airflow-1.9_spark-1.6"

- AIRFLOW_VERSION=1.9.0
  SPARK_VERSION=2.1.2
  HADOOP_VERSION=2.6.5
  SPARK_PY4J=python/lib/py4j-0.10.4-src.zip
  DOCKER_TAGS="airflow-1.9_spark-2.1 airflow-1.9"

- AIRFLOW_VERSION=1.10.0
  SPARK_VERSION=1.6.3
  HADOOP_VERSION=2.6.5
  SPARK_PY4J=python/lib/py4j-0.9-src.zip
  DOCKER_TAGS="airflow-1.10_spark-1.6 spark-1.6"

- AIRFLOW_VERSION=1.10.0
  SPARK_VERSION=2.1.2
  HADOOP_VERSION=2.6.5
  SPARK_PY4J=python/lib/py4j-0.10.4-src.zip
  DOCKER_TAGS="airflow-1.10_spark-2.1 airflow-1.10 spark-2.1 latest"

- DOCKER_TAGS=airflow-1.9_no-spark

- AIRFLOW_VERSION=1.10.0
  DOCKER_TAGS="airflow-1.10_no-spark no-spark"

install:
- docker build -t test-airflow:latest --no-cache
    --build-arg AIRFLOW_VERSION=${AIRFLOW_VERSION}
    --build-arg SPARK_VERSION=${SPARK_VERSION}
    --build-arg HADOOP_VERSION=${HADOOP_VERSION}
    --build-arg SPARK_PY4J=${SPARK_PY4J}
    --target with-spark .

script:
- docker-compose -f tests/docker-compose.test.yml up

after_success:
- if [ "$TRAVIS_EVENT_TYPE" == "push" ] && [ "$TRAVIS_BRANCH" == "master" ]; then
      docker login -u="$DOCKER_USER" -p="$DOCKER_PASS" ;
      ./build-and-push-docker.sh ;
  fi
